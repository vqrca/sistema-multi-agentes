# Sistema Multi-Agentes para Suporte da Hotmart ğŸ”¥

Sistema inteligente de atendimento ao cliente utilizando LLMs, RAG e Function Calling para responder perguntas sobre a Hotmart.

## ğŸ“š Ãndice

- [ğŸ—ï¸ Arquitetura do Sistema](#ï¸-arquitetura-do-sistema)
- [ğŸ§° Tecnologias utilizadas](#-tecnologias-utilizadas)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸš€ AplicaÃ§Ã£o online via Streamlit Cloud](#-teste-online-via-streamlit-cloud)
- [ğŸ” Como executar localmente com Docker](#-como-executar-localmente-com-docker)
- [ğŸ§ª Testes e Reprodutibilidade](#-testes-e-reprodutibilidade)
- [ğŸ“„ RelatÃ³rio Final](#-relatÃ³rio-final)

## ğŸ—ï¸ Arquitetura do Sistema

O sistema Ã© composto por 3 agentes principais:

* **Agente Central:** Gerencia a comunicaÃ§Ã£o e roteamento das conversas
* **Agente FAQ:** Busca informaÃ§Ãµes na base de conhecimento usando RAG
* **Agente Hotmart Journey:** Especialista em "ConheÃ§a a Hotmart Journey: Stars e Legacy" com acesso a dados personalizados de usuÃ¡rios

Este sistema foi desenvolvido para simular um atendimento inteligente multi-agente usando inteligÃªncia artificial generativa. Ele identifica o tipo de pergunta feita por um usuÃ¡rio e direciona a consulta para o agente mais adequado.

O fluxo geral segue estes passos:

<p align="left">
  <img src="https://raw.githubusercontent.com/vqrca/sistema-multi-agentes/main/Imagens/fluxo.png" width="70%"/>
</p>

1. UsuÃ¡rio envia uma pergunta via interface Streamlit.

2. Um Agente Central analisa a pergunta e faz uma classificaÃ§Ã£o:

    * 'FAQ': para dÃºvidas gerais sobre a Hotmart (ex: funcionalidades, pagamentos, configuraÃ§Ãµes)

    * 'JOURNEY': para perguntas sobre o programa Hotmart Journey: Stars e Legacy (ex: benefÃ­cios, faturamento, status do usuÃ¡rio)

3. A pergunta Ã© entÃ£o repassada para o agente adequado:

4. O Agente FAQ consulta a base vetorial FAISS com os artigos da FAQ e retorna uma resposta clara e objetiva.

5. O Agente Journey acessa dados fictÃ­cios de usuÃ¡rios (com base no ID) e retorna uma resposta especÃ­fica sobre o programa e seus benefÃ­cios.

6. A resposta Ã© exibida diretamente na interface para o usuÃ¡rio.

## ğŸ§  ConstruÃ§Ã£o da base vetorial (FAQ)
A base de conhecimento utilizada pelo agente de FAQ foi construÃ­da a partir de uma planilha contendo os artigos da Hotmart. O processo envolveu as seguintes etapas:

* **Carregamento dos dados:** a planilha foi carregada utilizando a biblioteca pandas;

* **EstruturaÃ§Ã£o dos documentos:** cada artigo foi transformado em um documento contendo o conteÃºdo do texto e seus metadados (nome do artigo e URL) com a biblioteca LlamaIndex;

* **GeraÃ§Ã£o dos embeddings:** os documentos passaram pelo processo de Embedding por meio do modelo `intfloat/multilingual-e5-large`, da `HuggingFaceEmbedding`; 

* **IndexaÃ§Ã£o vetorial:** os embeddings gerados foram armazenados em um banco vetorial utilizando o FAISS, permitindo que o agente de FAQ recupere os artigos mais relevantes com base na similaridade com a pergunta do usuÃ¡rio.


## ğŸ§° Tecnologias utilizadas

Este projeto foi desenvolvido com as seguintes tecnologias:

| Tecnologia | DescriÃ§Ã£o |
|------------|-----------|
| **LLM via Groq**<br>`llama-3.3-70b-versatile` | Modelo de linguagem de alta performance utilizado para interpretar perguntas, classificar rotas e gerar respostas |
| **HuggingFace Embeddings**<br>`intfloat/multilingual-e5-large` | Modelo de embeddings multilÃ­ngue utilizado para converter perguntas e documentos em vetores semÃ¢nticos |
| **LlamaIndex** | Framework para conectar LLMs a fontes externas de dados e orquestrar buscas contextuais (RAG) |
| **FAISS** | Biblioteca de busca vetorial rÃ¡pida e eficiente usada para construir a base de conhecimento da FAQ |
| **CrewAI** | Sistema de orquestraÃ§Ã£o multi-agente para executar tarefas distribuÃ­das entre agentes inteligentes |
| **Streamlit** | Ferramenta para criaÃ§Ã£o de interfaces web rÃ¡pidas e interativas, usada na prototipaÃ§Ã£o do sistema |
| **Docker & Docker Compose** | Utilizados para empacotar, isolar e facilitar a execuÃ§Ã£o local do ambiente de testes |


## ğŸ“ Estrutura do Projeto

```bash
projeto/
â”œâ”€â”€ Dockerfile                        # Define o ambiente Docker com Streamlit
â”œâ”€â”€ docker-compose.yaml               # Orquestra o container Docker e expÃµe a aplicaÃ§Ã£o
â”œâ”€â”€ .env                              # Armazena a chave de API
â”œâ”€â”€ testes/
â”‚   â””â”€â”€ perguntas_exemplo.txt         # Arquivo com perguntas de FAQ e Journey para serem testadas
â”œâ”€â”€ faiss_index/                      # Arquivos da base vetorial de conhecimento (gerados com FAISS)
â”œâ”€â”€ agentes.py                        # Define o agente central, agente de FAQ e agente do programa Hotmart Journey
â”œâ”€â”€ App.py                            # Interface com Streamlit para testar o protÃ³tipo via web
â”œâ”€â”€ vector_index.py                   # Carregamento dos Ã­ndices da base de conhecimento com embeddings do Hugging Face
â”œâ”€â”€ ferramentas.py                    # Ferramentas utilizadas pelos agentes 
â”œâ”€â”€ main_agent_router.py              # LÃ³gica de roteamento da pergunta, definindo qual agente serÃ¡ acionado
â”œâ”€â”€ mock_data.py                      # Dados de usuÃ¡rios fictÃ­cios   
â”œâ”€â”€ requirements.txt                  # DependÃªncias necessÃ¡rias para rodar o projeto
â””â”€â”€ README.md                         # DocumentaÃ§Ã£o geral do projeto
```

## ğŸš€ Teste online via Streamlit Cloud

A aplicaÃ§Ã£o estÃ¡ disponÃ­vel para uso direto no navegador â€” nÃ£o Ã© necessÃ¡rio instalar nada localmente.

ğŸ‘‰ [Clique aqui para acessar no Streamlit Cloud](https://sistema-multi-agentes-atendimento.streamlit.app/)

VocÃª pode testar o sistema com perguntas gerais ou personalizadas utilizando IDs.

ğŸ” **Importante:** A aplicaÃ§Ã£o jÃ¡ conta com uma chave de API da Groq, adicionada de forma segura e secreta ao ambiente do projeto. Isso permite que vocÃª explore todas as funcionalidades normalmente, sem se preocupar com autenticaÃ§Ã£o ou configuraÃ§Ã£o manual.

---

## ğŸ” Como executar localmente com Docker

Este projeto foi desenvolvido para ser facilmente executado usando Docker e Docker Compose. Siga os passos abaixo para rodar a aplicaÃ§Ã£o localmente:

### âœ… PrÃ©-requisitos

- Docker instalado: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)
- Docker Compose (jÃ¡ incluÃ­do nas versÃµes atuais do Docker)

---

### ğŸš€ Passo a passo

#### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/vqrca/sistema-multi-agentes.git
cd sistema-multi-agentes/projeto
```

#### 2. Configure a chave de API da Groq
No diretÃ³rio projeto, edite o arquivo `.env` (jÃ¡ presente no repositÃ³rio) e adicione a sua [chave de API da Groq](https://console.groq.com/keys) na variÃ¡vel GROQ_API_KEY:
```bash
GROQ_API_KEY=coloque_sua_chave_aqui
```
ğŸ” Essa variÃ¡vel serÃ¡ utilizada de forma segura no ambiente da aplicaÃ§Ã£o.

#### 3. Construa e execute a aplicaÃ§Ã£o
```bash
docker-compose up --build
```
A aplicaÃ§Ã£o serÃ¡ executada na porta 8501. Acesse no navegador:
http://localhost:8501

## ğŸ§ª Testes e Reprodutibilidade

Para facilitar os testes da aplicaÃ§Ã£o, este repositÃ³rio inclui exemplos de perguntas que podem ser usadas tanto para dÃºvidas gerais quanto para consultas personalizadas com ID de usuÃ¡rio.

#### ğŸ“‚ Arquivos disponÃ­veis

- `testes/perguntas_exemplo.txt`: contÃ©m um conjunto de perguntas prontas para copiar e colar na interface.

## ğŸ“„ RelatÃ³rio Final
Para complementar a entrega, foi elaborado um relatÃ³rio detalhado com a estratÃ©gia de validaÃ§Ã£o, mÃ©tricas utilizadas e uma anÃ¡lise da qualidade das respostas geradas pelos agentes.

ğŸ‘‰ [Clique aqui para acessar o relatÃ³rio final](https://github.com/vqrca/sistema-multi-agentes/blob/main/relatorio_final.md)

O relatÃ³rio aborda como o sistema lida com perguntas ambÃ­guas, como os agentes sÃ£o avaliados com base em relevÃ¢ncia e precisÃ£o, e apresenta sugestÃµes para evoluÃ§Ã£o futura do protÃ³tipo.

Este projeto demonstra como agentes inteligentes, combinados com LLMs e tÃ©cnicas de RAG, podem ser aplicados para melhorar o suporte ao cliente de forma personalizada e escalÃ¡vel. A arquitetura modular permite fÃ¡cil expansÃ£o para novos domÃ­nios e fluxos de atendimento.

Mais do que um protÃ³tipo funcional, esta soluÃ§Ã£o propÃµe uma abordagem realista e reprodutÃ­vel para construir sistemas conversacionais baseados em conhecimento, com atenÃ§Ã£o Ã  qualidade, relevÃ¢ncia e capacidade de adaptaÃ§Ã£o.



