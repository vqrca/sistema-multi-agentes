# Sistema Multi-Agentes para Suporte Hotmart

Sistema inteligente de atendimento ao cliente utilizando LLMs, RAG e Function Calling para responder perguntas sobre a Hotmart.

## üèóÔ∏è Arquitetura do Sistema

O sistema √© composto por 3 agentes principais:

* **Agente Central:** Gerencia a comunica√ß√£o e roteamento das conversas
* **Agente FAQ:** Busca informa√ß√µes na base de conhecimento usando RAG
* **Agente Hotmart Journey:** Especialista em "Conhe√ßa a Hotmart Journey: Stars e Legacy" com acesso a dados personalizados de usu√°rios

Este sistema foi desenvolvido para simular um atendimento inteligente multi-agente usando intelig√™ncia artificial generativa. Ele identifica o tipo de pergunta feita por um usu√°rio e direciona a consulta para o agente mais adequado.

O fluxo geral segue estes passos:

<p align="left">
  <img src="https://raw.githubusercontent.com/vqrca/sistema-multi-agentes/main/Imagens/fluxo.png" width="70%"/>
</p>

1. Usu√°rio envia uma pergunta via interface Streamlit.

2. Um Agente Central analisa a pergunta e faz uma classifica√ß√£o:

* 'FAQ': para d√∫vidas gerais sobre a Hotmart (ex: funcionalidades, pagamentos, configura√ß√µes)

* 'JOURNEY': para perguntas sobre o programa Hotmart Journey: Stars e Legacy (ex: benef√≠cios, faturamento, status do usu√°rio)

3. A pergunta √© ent√£o repassada para o agente adequado:

4. O Agente FAQ consulta a base vetorial FAISS com os artigos da FAQ e retorna uma resposta clara e objetiva.

5. O Agente Journey acessa dados fict√≠cios de usu√°rios (com base no ID) e retorna uma resposta espec√≠fica sobre o programa e seus benef√≠cios.

6. A resposta √© exibida diretamente na interface para o usu√°rio.


## üß∞ Tecnologias utilizadas

Este projeto foi desenvolvido com foco em modularidade, performance e reprodutibilidade. As principais tecnologias utilizadas s√£o:

| Tecnologia | Descri√ß√£o |
|------------|-----------|
| **LLM via Groq**<br>`llama-3.3-70b-versatile` | Modelo de linguagem de alta performance utilizado para interpretar perguntas, classificar rotas e gerar respostas |
| **HuggingFace Embeddings**<br>`intfloat/multilingual-e5-large` | Modelo de embeddings multil√≠ngue utilizado para converter perguntas e documentos em vetores sem√¢nticos |
| **LlamaIndex** | Framework para conectar LLMs a fontes externas de dados e orquestrar buscas contextuais (RAG) |
| **FAISS** | Biblioteca de busca vetorial r√°pida e eficiente usada para construir a base de conhecimento da FAQ |
| **CrewAI** | Sistema de orquestra√ß√£o multi-agente para executar tarefas distribu√≠das entre agentes inteligentes |
| **Streamlit** | Ferramenta para cria√ß√£o de interfaces web r√°pidas e interativas, usada na prototipa√ß√£o do sistema |
| **Docker & Docker Compose** | Utilizados para empacotar, isolar e facilitar a execu√ß√£o local do ambiente de testes |


## üìÅ Estrutura do Projeto

```bash
projeto/
‚îú‚îÄ‚îÄ Dockerfile             # Define o ambiente Docker com Streamlit
‚îú‚îÄ‚îÄ docker-compose.yaml    # Orquestra o container Docker e exp√µe a aplica√ß√£o
‚îú‚îÄ‚îÄ .env                   # Armazena a chave de API
‚îú‚îÄ‚îÄ exemplos/
‚îÇ   ‚îî‚îÄ‚îÄ testes.sh          # Script para simular perguntas de FAQ e Journey via cURL
‚îú‚îÄ‚îÄ faiss_index/           # Arquivos da base vetorial de conhecimento (gerados com FAISS)
‚îú‚îÄ‚îÄ agentes.py             # Define o agente central, agente de FAQ e agente do programa Hotmart Journey
‚îú‚îÄ‚îÄ App.py                 # Interface com Streamlit para testar o prot√≥tipo via web
‚îú‚îÄ‚îÄ vector_index.py        # Carregamento dos √≠ndices da base de conhecimento com embeddings do Hugging Face
‚îú‚îÄ‚îÄ ferramentas.py         # Ferramentas utilizadas pelos agentes (ex: busca FAISS, API mockada)
‚îú‚îÄ‚îÄ main_agent_router.py   # L√≥gica de roteamento da pergunta, definindo qual agente ser√° acionado
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias necess√°rias para rodar o projeto
‚îî‚îÄ‚îÄ README.md              # Documenta√ß√£o geral do projeto
```

## üöÄ Teste online via Streamlit Cloud

Voc√™ pode acessar a aplica√ß√£o diretamente, sem precisar instalar nada localmente.

üëâ [Clique aqui para acessar no Streamlit Cloud](https://sistema-multi-agentes.streamlit.app)

> A aplica√ß√£o est√° hospedada e pronta para testes com perguntas gerais e personalizadas usando IDs.

---

## üîÅ Como executar localmente com Docker

Este projeto foi desenvolvido para ser facilmente executado usando Docker e Docker Compose. Siga os passos abaixo para rodar a aplica√ß√£o localmente:

### ‚úÖ Pr√©-requisitos

- Docker instalado: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)
- Docker Compose (j√° inclu√≠do nas vers√µes atuais do Docker)

---

### üöÄ Passo a passo

#### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/vqrca/sistema-multi-agentes.git
cd sistema-multi-agentes
```

#### 2. Construa e execute a aplica√ß√£o
```bash
docker-compose up --build
```
A aplica√ß√£o ser√° executada na porta 8501. Acesse no navegador:
http://localhost:8501

## üß™ Testes e Reprodutibilidade

Para facilitar os testes da aplica√ß√£o, este reposit√≥rio inclui exemplos de perguntas que podem ser usadas tanto para d√∫vidas gerais quanto para consultas personalizadas com ID de usu√°rio.

### üìÇ Arquivos dispon√≠veis

- `testes/perguntas_exemplo.txt`: cont√©m um conjunto de perguntas prontas para copiar e colar na interface.
- `testes/abrir_app.sh`: script shell para abrir automaticamente a aplica√ß√£o no navegador local (`http://localhost:8501`).

### ‚ñ∂Ô∏è Como testar

1. Ap√≥s executar o projeto com Docker (veja se√ß√£o anterior), rode no terminal:

```bash
bash testes/abrir_app.sh
```

2. Em seguida, visualize as perguntas de teste com:
```bash
cat testes/perguntas_exemplo.txt
```



